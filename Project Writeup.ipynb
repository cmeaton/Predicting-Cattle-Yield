{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connor Eaton**\n",
    "\n",
    "Metis - Project Luther - January 25th, 2019\n",
    "\n",
    "\n",
    "\n",
    "# Predicting beef cattle production\n",
    "\n",
    "### Why is this important?\n",
    "Meat production, and particularily beef cattle, is a very interconnected, complex, and expensive process that is crucial to local and global economies. The complexities of its production stem from the fact that before one can raise cattle, one must raise its food. While cattle are natural ruminants, improvements in agricultural processes starting in the mid 20th century have trended towards the production of corn and soy for cattle feed. \n",
    "\n",
    "This makes raising and harvesting cattle reliant upon multiple sectors of the global agricultural industry. Despite its complexity and expense, demand for beef cattle has been rising world wide. As a result, I am posing the following questions:\n",
    "\n",
    "**1.) Can total production of beef per country in a given year can be predicted?**\n",
    "\n",
    "**2.) If so, what features most strongly predict production? **\n",
    "\n",
    "Digging into these questions with regression analysis may improve our understanding and optimization of our global food production sytem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pycountry\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data:\n",
    "\n",
    "I used multiple data sources for this project, listed below:\n",
    "\n",
    "\n",
    "*Food and Agriculture Organization.* \n",
    "http://www.fao.org/faostat/en/#data\n",
    "\n",
    "Many .csv files were gathered here and required cleaning and merging. \n",
    "\n",
    "    - Total head of cattle (living)\n",
    "    - Total area in soy production (hectares)\n",
    "    - Total yield of soy (hectagrams per hectares)\n",
    "    - Total area in corn production (hectares)\n",
    "    - Total yield of corn (hectagrams per hectares)\n",
    "    - Mean weight of harvested cattle (hectagrams per animal)\n",
    "    - Total number of harvested cattle\n",
    "    - Total human population in rural areas per country\n",
    "    - Total human population in urban areas per country\n",
    "\n",
    "*Weather from the WorldBank.*\n",
    "http://sdwebx.worldbank.org/climateportal/index.cfm?page=downscaled_data_download&menu=historical\n",
    "\n",
    "**Selenium was used to scrape this data**. The wesbite was structured with multiple drop down menus with a variety of categories. Once all the desired categories were selected, a few buttons had to be clicked and then a .xls file on the data could be downloaded to your machine. My selenium bot iterated through every drop down menu selection for each country and navigated the necassary pages to download each country-specific .xls file. Much cleaning, as well as using the pycountry library, was necassary to make the data usable in my project.\n",
    "\n",
    "    - Cumulative precipitation data\n",
    "    \n",
    "*Consumption and Production Data from Our World in Data.*\n",
    "https://ourworldindata.org/meat-and-seafood-production-consumption\n",
    "\n",
    "Two .csv files were gathered here and required cleaning and merging. \n",
    "\n",
    "    - Production of beef.\n",
    "    - Consumption of beef per capita\n",
    "    \n",
    "*GDP data from the WorldBank.*\n",
    "https://data.worldbank.org/indicator/NY.GDP.MKTP.CD\n",
    "\n",
    "One .csv files were gathered here and required cleaning and merging. \n",
    "\n",
    "    - GDP per country \n",
    "    \n",
    "Upon merging and cleaning all of this data into one dataframe, I had **~2900 observations and 13 features** to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data:\n",
    "\n",
    "**Normalization**. Data were in a variety of scales (ex. GDP(10e+8) and hg/animal(800-1200)). I manually adjusted data to be on the same order of magnitude. \n",
    "\n",
    "**Removal of outliers**. Outliers were removed for certain variables.\n",
    "\n",
    "**Categorical features**. Categorical data (country name) was converted to GDP. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering:\n",
    "\n",
    "**Log transforms**. The y variable was log transformed so it depicted a more normal distribution. Several features were log transformed to bring residual plots closer to 0.\n",
    "\n",
    "**Dummy variables** Dummy variables were created for China, Brazil, and India, who all had large effects on the data. Ultimately, India was entirely dropped from the dataset, and the Brazil dummy was dropped from the model. Much future work is needed here and is described later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction\n",
    "\n",
    "**LassoCV and RidgeCV**\n",
    "\n",
    "To properly build an accurate model, I used cross validation with my training datasplit into 5 folds. I will do this with Lasso and Ridge regression and compare results. Lasso and Ridge regression were used and compared. Both models produced nearly identical metrics (MAE, alpha, and feature coefficents), but Ridge was selected as the r2 was slightly higher.\n",
    "\n",
    "**Regularization**\n",
    "\n",
    "Features with coefficents zeroed by my model were eliminated. Features with coefficents close to 0 were removed one by one too see how simple I get the model to be without losing efficacy. The final model had the following features: *cattle_head, soy_area_ha, soy_area_hg/ha, harvest_number,corn_area_ha, corn_hg/ha, urban_pop_e+01, GDP_e+05, supply_g/capita, 'China, and Brazil*.\n",
    "\n",
    "**Final Model**\n",
    "\n",
    "My final model was trained on the previously untouched test data. The mean absolute error for my model was 13.08  This however is in log form. Calculating it back into its original scale, the MAE was is 479,269. This seems very high, but this is because of the large values in the y data. The range of data fell between 0 and 85,118,939, so this value seems appropriate.\n",
    "\n",
    "The r2 score was .887, indicating strong predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "There is plenty of opportunity for future work. Idealy, I would like to improve two factors of the project.\n",
    "\n",
    "**Interaction features**\n",
    "\n",
    "Creating dummy variables for China, Brazil, and India, and incorporating the China feature in my model, had a positive effect on my model. However, I did not have the time to explore interaction between this feature and others. My residual plot indicates several patterns straying from the cluster around 0, indicating potential for creating interaction features from countries, to improve my model.\n",
    "\n",
    "**Tranformation of features**\n",
    "\n",
    "Log transformations had a positive effect in centering residual plots closer to 0 for several plots. However, there were still clear patterns present in the transformed data. One of the patterns was the straying from 0 described above. The other was a tendency for the residuals to be further from 0 as the feature grew larger. I would like to dig further into this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
